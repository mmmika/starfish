{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starfish BaristaSeq Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "from skimage.transform import SimilarityTransform, warp\n",
    "from tqdm import tqdm\n",
    "\n",
    "import starfish\n",
    "import starfish.data\n",
    "from starfish.spots import SpotFinder\n",
    "from starfish.types import Axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaristaSeq is an assay that sequences padlock-probe initiated rolling circle amplified spots using a one-hot codebook. The publication for this assay can be found [here](https://www.ncbi.nlm.nih.gov/pubmed/29190363).\n",
    "\n",
    "here we select data for a single field of view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 61.75it/s]\n"
     ]
    }
   ],
   "source": [
    "exp = starfish.Experiment.from_json(os.path.expanduser(\"~/scratch/baristaseq/experiment.json\"))\n",
    "nissl = exp['fov_000'].get_image('dots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:07<00:00, 61.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# exp = starfish.data.BaristaSeq()\n",
    "img = exp['fov_000'].get_image('primary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in BaristaSeq is to do some rough registration. For this data, the rough registration has been done for us by the authors, so it is omitted from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project into 2D\n",
    "\n",
    "First, project the z-plane to do analysis of BaristaSeq in 2-d. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 207.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 195.01it/s]\n"
     ]
    }
   ],
   "source": [
    "z_projected_image = img.max_proj(Axes.ZPLANE)\n",
    "z_projected_nissl = nissl.max_proj(Axes.ZPLANE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Channel Misalignment\n",
    "\n",
    "There is a slight miss-alignment of the C channel in the microscope used to process the data. This has been corrected for this data, but here is how it could be transformed using python code for future datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.feature import register_translation\n",
    "# from skimage.transform import warp\n",
    "# from skimage.transform import SimilarityTransform\n",
    "# from functools import partial\n",
    "\n",
    "# # Define the translation\n",
    "# transform = SimilarityTransform(translation=(1.9, -0.4))\n",
    "\n",
    "# # C is channel 0\n",
    "# channels = (0,)\n",
    "\n",
    "# # The channel should be transformed in all rounds\n",
    "# rounds = np.arange(img.num_rounds)\n",
    "\n",
    "# # apply the transformation in place\n",
    "# slice_indices = product(channels, rounds)\n",
    "# for ch, round_, in slice_indices:\n",
    "#     selector = {Axes.ROUND: round_, Axes.CH: ch, Axes.ZPLANE: 0}\n",
    "#     tile = z_projected_image.get_slice(selector)[0]\n",
    "#     transformed = warp(tile, transform)\n",
    "#     z_projected_image.set_slice(\n",
    "#         selector=selector,\n",
    "#         data=transformed.astype(np.float32),\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Registration Artefacts\n",
    "\n",
    "There are some minor registration errors along the pixels for which y < 100 and x < 50. Those pixels are dropped from this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_corrected = z_projected_image.sel({Axes.Y: (100, -1), Axes.X: (50, -1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct for bleed-through from Illumina SBS reagents\n",
    "\n",
    "The following matrix contains bleed correction factors for Illumina sequencing-by-synthesis reagents. Starfish provides a LinearUnmixing method that will unmix the fluorescence intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bleed_to</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bleed_from</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bleed_to       0     1     2     3\n",
       "bleed_from                        \n",
       "0           0.00  0.05  0.00  0.00\n",
       "1           0.35  0.00  0.00  0.00\n",
       "2           0.00  0.02  0.00  0.84\n",
       "3           0.00  0.00  0.05  0.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(\n",
    "    [[0.  , 0.05, 0.  , 0.  ],\n",
    "     [0.35, 0.  , 0.  , 0.  ],\n",
    "     [0.  , 0.02, 0.  , 0.84],\n",
    "     [0.  , 0.  , 0.05, 0.  ]]\n",
    ")\n",
    "rows = pd.Index(np.arange(4), name='bleed_from')\n",
    "cols = pd.Index(np.arange(4), name='bleed_to')\n",
    "unmixing_coeff = pd.DataFrame(data, rows, cols)\n",
    "\n",
    "# show results\n",
    "unmixing_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lum = starfish.image._filter.linear_unmixing.LinearUnmixing(unmixing_coeff)\n",
    "bleed_corrected = lum.run(registration_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove image background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove image background, BaristaSeq uses a White Tophat filter, which measures the background with a rolling disk morphological element and subtracts it from the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import opening, dilation, disk\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If desired, the background that is being subtracted can be visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening = partial(opening, selem=disk(5))\n",
    "\n",
    "# background = bleed_corrected.apply(\n",
    "#     opening,\n",
    "#     group_by={Axes.ROUND, Axes.CH, Axes.ZPLANE}, verbose=False, in_place=False\n",
    "# )\n",
    "\n",
    "# starfish.display(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wth = starfish.image.Filter.WhiteTophat(masking_radius=5)\n",
    "background_corrected = wth.run(bleed_corrected, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale images to equalize spot intensities across channels\n",
    "\n",
    "The number of peaks are not uniform across rounds and channels, which prevents histogram matching across channels. Instead, a percentile value is identified and set as the maximum across channels, and the dynamic range is extended to equalize the channel intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp = starfish.image.Filter.ScaleByPercentile(p=99.5)\n",
    "scaled = sbp.run(background_corrected, n_processes=1, in_place=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1d06fe7b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove residual background\n",
    "\n",
    "The background is fairly uniformly present below intensity=0.5. However, starfish's clip method currently only supports percentiles. To solve this problem, the intensities can be directly edited in the underlying numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "clipped = deepcopy(scaled)\n",
    "clipped.xarray.values[clipped.xarray.values < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x2225e0550>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(clipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Spots\n",
    "\n",
    "Detect spots with a local search blob detector that identifies spots in all rounds and channels and matches them using a local search method. The local search starts in an anchor channel (default ch=1) and identifies the nearest spot in all subsequent imaging rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "lsbd = starfish.spots._detector.local_search_blob_detector.LocalSearchBlobDetector(\n",
    "    min_sigma=(0.5, 0.5, 0.5),\n",
    "    max_sigma=(8, 8, 8),\n",
    "    num_sigma=10,\n",
    "    threshold=threshold,\n",
    "    search_radius=7\n",
    ")\n",
    "intensities = lsbd.run(clipped)\n",
    "decoded = exp.codebook.decode_per_round_max(intensities.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x2304ba208>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(clipped, intensities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on visual inspection, it looks like the spot correspondence across rounds isn't being detected well. Try the PixelSpotDecoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1698/1698 [00:03<00:00, 500.74it/s]\n"
     ]
    }
   ],
   "source": [
    "psd = starfish.spots.PixelSpotDecoder.PixelSpotDecoder(\n",
    "    codebook=exp.codebook, metric='euclidean', distance_threshold=0.5, \n",
    "    magnitude_threshold=0.1, min_area=7, max_area=50\n",
    ")\n",
    "pixel_decoded, ccdr = psd.run(clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajc/projects/spacetx/starfish/starfish/imagestack/imagestack.py:324: UserWarning: ImageStack detected as int64. Converting to float32...\n",
      "  warnings.warn(f\"ImageStack detected as {array.dtype}. Converting to float32...\")\n",
      "/Users/ajc/projects/spacetx/starfish/.venv/lib/python3.6/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from int64 to float32\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "100%|██████████| 1/1 [00:00<00:00, 167.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1d8450f98>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_image = starfish.ImageStack.from_numpy_array(np.reshape(ccdr.label_image, (1, 1, 1, 1092, 862)))\n",
    "starfish.display(label_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the number of spots being detected by the two spot finders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_decoder spots detected 1618\n",
      "local search spot detector spots detected 1454\n"
     ]
    }
   ],
   "source": [
    "print(\"pixel_decoder spots detected\", int(np.sum(pixel_decoded['target'] != 'nan')))\n",
    "print(\"local search spot detector spots detected\", int(np.sum(decoded['target'] != 'nan')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the correlation between the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1868014722522533, 0.20361878324966726)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# get the total counts for each gene from each spot detector\n",
    "pixel_decoded_gene_counts = pd.Series(*np.unique(pixel_decoded['target'], return_counts=True)[::-1])\n",
    "decoded_gene_counts = pd.Series(*np.unique(decoded['target'], return_counts=True)[::-1])\n",
    "\n",
    "# get the genes that are detected by both spot finders\n",
    "codetected = pixel_decoded_gene_counts.index.intersection(decoded_gene_counts.index)\n",
    "\n",
    "# report the correlation\n",
    "pearsonr(pixel_decoded_gene_counts[codetected], decoded_gene_counts[codetected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel based spot detector looks better upon visual inspection. Do the below values make sense for this tissue and this probeset?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nxph1         1\n",
       "Neurod6       1\n",
       "Pdgfra        1\n",
       "Ndnf          1\n",
       "Penk          1\n",
       "Plpp4         1\n",
       "Cnr1          1\n",
       "Dlx1          1\n",
       "Dcn           1\n",
       "Pcp4          2\n",
       "Itpka         2\n",
       "Fgfr3         2\n",
       "Ankrd55       2\n",
       "Snrpn         2\n",
       "Kcnmb2        3\n",
       "Nxph4         3\n",
       "Nrn1          3\n",
       "Rprml         3\n",
       "Id2           3\n",
       "Pvalb         3\n",
       "Tesc          4\n",
       "Rorb          4\n",
       "Sncg          4\n",
       "Cxcl14        4\n",
       "Fezf2         4\n",
       "Sparcl1       5\n",
       "Caln1         6\n",
       "Arx           6\n",
       "Npy           6\n",
       "Reln          6\n",
       "Slc6a1        7\n",
       "Nfib          7\n",
       "Slc17a7       9\n",
       "Sst          11\n",
       "Kcnip1       11\n",
       "Vxn          17\n",
       "Rab3b        18\n",
       "Sv2b         19\n",
       "Cacna2d3     24\n",
       "Dlx6         24\n",
       "Crh          27\n",
       "Ly6c2        28\n",
       "Nrgn         32\n",
       "Cck          35\n",
       "Ptprd        42\n",
       "Car4         44\n",
       "Synpr        51\n",
       "Neurod1      54\n",
       "Igfbp6       59\n",
       "nan          80\n",
       "Arpp19      134\n",
       "Brinp3      135\n",
       "Ptn         195\n",
       "Ctxn1       549\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_decoded_gene_counts.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Codebook (target: 1, c: 4, r: 7)>\n",
       "array([[[1, 0, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 1, 0, 0, 0, 0]]], dtype=uint8)\n",
       "Coordinates:\n",
       "  * target   (target) object 'Ctxn1'\n",
       "  * c        (c) int64 0 1 2 3\n",
       "  * r        (r) int64 0 1 2 3 4 5 6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.codebook[np.where(exp.codebook[\"target\"] == \"Ctxn1\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Codebook (target: 1, c: 4, r: 7)>\n",
       "array([[[0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 0]]], dtype=uint8)\n",
       "Coordinates:\n",
       "  * target   (target) object 'Ptn'\n",
       "  * c        (c) int64 0 1 2 3\n",
       "  * r        (r) int64 0 1 2 3 4 5 6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.codebook[np.where(exp.codebook[\"target\"] == \"Ptn\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Codebook (target: 1, c: 4, r: 7)>\n",
       "array([[[0, 1, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 1]]], dtype=uint8)\n",
       "Coordinates:\n",
       "  * target   (target) object 'Brinp3'\n",
       "  * c        (c) int64 0 1 2 3\n",
       "  * r        (r) int64 0 1 2 3 4 5 6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.codebook[np.where(exp.codebook[\"target\"] == \"Brinp3\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the codebook targets from PixelSpotDecoding don't share much in the way of channel biases across rounds or across codes, which makes me reasonably confident in the decoding result. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starfish",
   "language": "python",
   "name": "starfish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
