{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starfish BaristaSeq Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "from skimage.transform import SimilarityTransform, warp\n",
    "from tqdm import tqdm\n",
    "\n",
    "import starfish\n",
    "import starfish.data\n",
    "from starfish.spots import SpotFinder\n",
    "from starfish.types import Axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaristaSeq is an assay that sequences padlock-probe initiated rolling circle amplified spots using a one-hot codebook. The publication for this assay can be found [here](https://www.ncbi.nlm.nih.gov/pubmed/29190363).\n",
    "\n",
    "The first step in BaristaSeq is to do some rough registration. For this data, the rough registration has been done for us by the authors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1550ad7b8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 61.49it/s]\n"
     ]
    }
   ],
   "source": [
    "exp = starfish.Experiment.from_json(os.path.expanduser(\"~/scratch/baristaseq/experiment.json\"))\n",
    "nissl = exp['fov_000'].get_image('dots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:07<00:00, 61.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# exp = starfish.data.BaristaSeq()\n",
    "img = exp['fov_000'].get_image('primary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1103c6f98>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of BaristaSeq is done in 2-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x15aa95550>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(nissl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 192.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 177.65it/s]\n"
     ]
    }
   ],
   "source": [
    "z_projected_image = img.max_proj(Axes.ZPLANE)\n",
    "z_projected_nissl = nissl.max_proj(Axes.ZPLANE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight miss-alignment of the C channel in the microscope used to process the data. We transform the data to account for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SimilarityTransform(translation=(1.9, -0.4))\n",
    "channels = (0,)\n",
    "rounds = np.arange(img.num_rounds)\n",
    "slice_indices = product(channels, rounds)\n",
    "\n",
    "for ch, round_, in slice_indices:\n",
    "    selector = {Axes.ROUND: round_, Axes.CH: ch, Axes.ZPLANE: 0}\n",
    "    tile = z_projected_image.get_slice(selector)[0]\n",
    "    transformed = warp(tile, transform)\n",
    "    z_projected_image.set_slice(\n",
    "        selector=selector,\n",
    "        data=transformed.astype(np.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 188.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from skimage.feature import register_translation  # noqa\n",
    "from skimage.transform import warp  # noqa\n",
    "from skimage.transform import SimilarityTransform  # noqa\n",
    "from functools import partial\n",
    "\n",
    "def _register_imagestack(target_image, reference_image, upsample_factor=5):\n",
    "    target_image = np.squeeze(target_image)\n",
    "    reference_image = np.squeeze(reference_image)\n",
    "    shift, error, phasediff = register_translation(target_image, reference_image, upsample_factor=1)\n",
    "    return SimilarityTransform(translation=shift)\n",
    "\n",
    "projection = z_projected_image.max_proj(Axes.CH, Axes.ZPLANE)\n",
    "reference_image = projection.sel({Axes.ROUND: 1}).xarray\n",
    "\n",
    "register_imagestack = partial(\n",
    "    _register_imagestack, reference_image=reference_image, upsample_factor=5\n",
    ")\n",
    "transforms = projection.transform(register_imagestack, group_by={Axes.ROUND}, n_processes=1)\n",
    "round_to_tf = {axes[Axes.ROUND]: tf for tf, axes in transforms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x3cffe7630>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1., -2.]),\n",
       " array([0., 0.]),\n",
       " array([ 0., -1.]),\n",
       " array([ 1., -2.]),\n",
       " array([ 2., -2.]),\n",
       " array([ 2., -3.]),\n",
       " array([ 2., -2.])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.translation for t in round_to_tf.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 195.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# starfish doesn't have a great ability to apply different functions to different parts of an\n",
    "# imagestack based on their Axes. It would be great if one could iterate over the ImageStack\n",
    "# and apply a set of transformations to each tile based on the tile's coordinates.\n",
    "\n",
    "def _warp_tile(tile, transform):\n",
    "    round_ = int(tile.coords[Axes.ROUND.value])\n",
    "    return warp(np.squeeze(tile), transforms[round_])\n",
    "\n",
    "def warp_imagestack(imagestack, transform_set, chunk_by):\n",
    "\n",
    "    new = starfish.ImageStack.from_numpy_array(np.zeros_like(imagestack.xarray.values))\n",
    "\n",
    "    selectors = product(*(list(int(i) for i in imagestack.xarray.coords[c]) for c in chunk_by))\n",
    "    for s in selectors:\n",
    "        selector = dict(zip(chunk_by, s))\n",
    "        data = np.squeeze(imagestack.xarray.sel(selector))\n",
    "        res = warp(data, transform_set[selector[Axes.ROUND.value]])\n",
    "        new.set_slice(selector, res.astype(np.float32))\n",
    "\n",
    "    return new\n",
    "\n",
    "\n",
    "transformed = warp_imagestack(z_projected_image, round_to_tf, chunk_by=(\"r\", \"c\", \"z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x3cf9cab70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-pass filter to remove camera noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 266.95it/s]\n"
     ]
    }
   ],
   "source": [
    "ghp = starfish.image.Filter.GaussianHighPass(sigma=1)\n",
    "high_passed = ghp.run(z_projected_image, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct for bleed-through from Illumina SBS reagents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this can be replaced with Kevin's linear unmixing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 16.75it/s]\n"
     ]
    }
   ],
   "source": [
    "bleed_correction_factors = pd.DataFrame(\n",
    "    data=[\n",
    "        [0, 1, 0.05],\n",
    "        [0, 2, 0],\n",
    "        [0, 3, 0],\n",
    "        [1, 0, 0.35],\n",
    "        [1, 2, 0],\n",
    "        [1, 3, 0],\n",
    "        [2, 0, 0],\n",
    "        [2, 1, 0.02],\n",
    "        [2, 3, 0.84],\n",
    "        [3, 0, 0],\n",
    "        [3, 1, 0],\n",
    "        [3, 2, 0.05]\n",
    "    ],\n",
    "    columns=(('bleed_from', 'bleed_into', 'factor_bleed_from_into')),\n",
    ")\n",
    "\n",
    "\n",
    "def do_bleed_correction(stack):\n",
    "    bleed_corrected = deepcopy(stack)\n",
    "\n",
    "    for index, (ch1, ch2, constant) in tqdm(bleed_correction_factors.iterrows()):\n",
    "        bleed = stack.get_slice({Axes.CH: int(ch1)})[0] * constant\n",
    "        img_to_correct = stack.get_slice({Axes.CH: int(ch2)})[0]\n",
    "        corrected = np.maximum(img_to_correct - bleed, 0)\n",
    "        bleed_corrected.set_slice(\n",
    "            {Axes.CH: int(ch2)},\n",
    "            corrected,\n",
    "            axes=[Axes.ROUND, Axes.ZPLANE]\n",
    "        )\n",
    "    return bleed_corrected\n",
    "\n",
    "\n",
    "bleed_corrected = do_bleed_correction(transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove image background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x1055a3dd8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(bleed_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = starfish.image.Filter.Clip(p_min=90, p_max=99.9)\n",
    "clipped = clip.run(bleed_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x2585b3208>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wth = starfish.image.Filter.WhiteTophat(masking_radius=10)\n",
    "\n",
    "background_corrected = wth.run(bleed_corrected, in_place=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh = starfish.image.Filter.MatchHistograms(group_by={Axes.CH, Axes.ROUND})\n",
    "matched = mh.run(background_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x3cffeaa90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(matched.xarray.values, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsbd = starfish.spots._detector.local_search_blob_detector.LocalSearchBlobDetector(\n",
    "    min_sigma=(1, 1, 1),\n",
    "    max_sigma=(8, 8, 8),\n",
    "    num_sigma=10,\n",
    "    threshold=threshold,\n",
    "    search_radius=7\n",
    ")\n",
    "intensities = lsbd.run(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.components._viewer.model.Viewer at 0x3d5ad8710>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starfish.display(matched, intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.IntensityTable (features: 1076, c: 4, r: 7)>\n",
       "array([[[0.001821, 0.000753, ..., 0.002201,      nan],\n",
       "        [     nan,      nan, ...,      nan,      nan],\n",
       "        [     nan,      nan, ...,      nan,      nan],\n",
       "        [     nan,      nan, ...,      nan, 0.001116]],\n",
       "\n",
       "       [[     nan, 0.000878, ...,      nan,      nan],\n",
       "        [     nan,      nan, ..., 0.001201,      nan],\n",
       "        [0.002012,      nan, ...,      nan,      nan],\n",
       "        [     nan,      nan, ...,      nan, 0.002224]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.001072,      nan, ...,      nan,      nan],\n",
       "        [     nan,      nan, ...,      nan, 0.001083],\n",
       "        [     nan,      nan, ...,      nan,      nan],\n",
       "        [     nan, 0.001079, ...,      nan,      nan]],\n",
       "\n",
       "       [[     nan,      nan, ...,      nan,      nan],\n",
       "        [     nan,      nan, ...,      nan,      nan],\n",
       "        [     nan,      nan, ...,      nan,      nan],\n",
       "        [     nan, 0.000947, ..., 0.000945,      nan]]])\n",
       "Coordinates:\n",
       "    radius   (features) float64 629.5 549.2 685.3 568.7 ... 366.3 318.6 262.3\n",
       "    z        (features) int64 0 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n",
       "    y        (features) int64 1192 1186 1185 1181 1180 ... 373 325 283 173 116\n",
       "    x        (features) int64 694 459 869 521 695 724 ... 444 287 814 781 669\n",
       "  * r        (r) int64 0 1 2 3 4 5 6\n",
       "  * c        (c) int64 0 1 2 3\n",
       "    xc       (features) float32 0.00076096493 0.00050328946 ... 0.0007335526\n",
       "    yc       (features) float32 0.001 0.0009949665 ... 9.731544e-05\n",
       "    zc       (features) float32 0.0005 0.0005 0.0005 ... 0.0005 0.0005 0.0005\n",
       "Dimensions without coordinates: features\n",
       "Attributes:\n",
       "    starfish:  {\"log\": [{\"method\": \"WhiteTophat\", \"arguments\": {\"masking_radi..."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "?exp.codebook.decode_per_round_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = exp.codebook.decode_per_round_max(intensities.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'target' ()>\n",
       "array(92)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(~(decoded['target'] == 'nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = matched.xarray[0, 0, 0].values\n",
    "from skimage.feature import blob_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_log(test_arr, threshold=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starfish",
   "language": "python",
   "name": "starfish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
